{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0812c182",
   "metadata": {},
   "source": [
    "## flag1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3d8b3ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'This file contains all flags of misc-ransomware and some garbage data.\\r\\nM7cYYMoLfUg0OyGbSxLJ6n9AZt4U8CaCevNuJzpOTFQCptFuw4AY6m0k2rFkmoKwNdo63AsabM0zh7uEegR2XvKcEniQeJ4VPY0sHjekItUAAIYuAkdWpuEHoRZaZ9EdX4BwaGpvDiMoIy2S4yD1iuZYZN67S1Z6ErSmejIXFAf7V9lf0aHhFhemZHtE5flag{yOu_NeeD_somE_bAsIc_CRyPto_kNOwlEdgE_bEfORE_WRiTiNG_RANSoMWARE_gUHHI6jc6vTRXzg7J4UX}mAYp2MB2ByOvy7YesY4oKFLjfaTk8eZt7PwyqXh31DsdpIwvmtkn6bpUWLymn5DU6EzVG3GoigomgLKbmmfbEdd9Aym5nrWD3GgyFIt2d3KL5AtETib1n6lPOW34JIf3m2E6a3htdV5izMpMdTrgGU3XQDbRfr8AiWMG92An8ffVMNJyUkC2eFImwjwJ63A7CFUQb9eDcoJwVthgU2i9JxJceY5LAh3nc36QQGtMtDOOBsRfWWZVpk74HWdyJAna2fOe72k1I6LFrnND7gvBMWntBa6UyOPJoOMNRwHRBMoqoQNDAHt0ybBO1m3XXZi5i2CTTzfwxBxyJ2huSt9dOT10ur3B3YpAJp1Qi52VHADevnuSc6XgyeeiVL2d2kPlQY3vzgK40THAcmrcFH59FOSwbFBuLjSSDJRbOmJCCF0ZS8AcxFmk4xLasez4TgPA92tIZgckPuskGAuPIX7wDWi5thcKqsOn2Y1uyc2dyOV3bbXmjKpemZmnF70nNcvhGwCnWD9yMj9J9kzdLlBu9RbVkcMaR3tSYxpfyUOS49UW7mnmBHiOjbMRG2KGBc4ilMmYtVa8RuXnxukYfb8hKA9axnh6v23inX3mh0U9Ku7s80MGpcgWb9NB1RFEF8msYfBFDcAQ7NC52DzQrc91QlQjhMqa7ESmE2QdgVgh8DGDomhEmMrBwEq5gplRAksztZTUIo20ud9rtoqvZdzLlMTCg'\n"
     ]
    }
   ],
   "source": [
    "P_known = open('algo-gzip.py', 'rb').read()\n",
    "P_known = P_known.replace(b\"\\n\", b\"\\r\\n\")\n",
    "C_known = open('algo-gzip.f58A66B51.py', 'rb').read()\n",
    "\n",
    "keystream = bytes(p ^ c for p, c in zip(P_known, C_known)) # 1079字节\n",
    "\n",
    "C_flag = open('flag1-2-3.f58A66B51.txt', 'rb').read()\n",
    "P_flag = bytes([a^b for a,b in zip(keystream, C_flag)])\n",
    "print(P_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "daf6e853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1079, 1591, 1815)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(P_known), len(C_known), len(C_flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ec1add",
   "metadata": {},
   "source": [
    "## flag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "47491f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import os\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "def parse_local_file_header(data, offset):\n",
    "    \"\"\"解析ZIP文件的Local File Header\"\"\"\n",
    "    if len(data) - offset < 30:\n",
    "        raise ValueError(\"数据长度不足，无法解析Local File Header\")\n",
    "    \n",
    "    # 解析固定30字节的Header\n",
    "    signature, version, flags, compression, mod_time, mod_date, crc32, comp_size, uncomp_size, name_len, extra_len = \\\n",
    "        struct.unpack('<LHHHHHLLLHH', data[offset:offset+30])\n",
    "    \n",
    "    # 检查签名\n",
    "    if signature != 0x04034b50:\n",
    "        raise ValueError(f\"错误的Local File Header签名: 0x{signature:08x}\")\n",
    "    \n",
    "    # 读取文件名\n",
    "    name_start = offset + 30\n",
    "    name_end = name_start + name_len\n",
    "    filename = data[name_start:name_end].decode('utf-8', errors='replace')\n",
    "    \n",
    "    # 读取额外字段\n",
    "    extra_start = name_end\n",
    "    extra_end = extra_start + extra_len\n",
    "    \n",
    "    # 计算数据开始位置\n",
    "    data_start = extra_end\n",
    "    \n",
    "    return {\n",
    "        'offset': offset,\n",
    "        'signature': f'0x{signature:08x}',\n",
    "        'version_needed': (version >> 8) + (version & 0xFF) / 10,\n",
    "        'flags': flags,\n",
    "        'compression_method': compression,\n",
    "        'compression_name': get_compression_name(compression),\n",
    "        'mod_time': parse_dos_time(mod_time, mod_date),\n",
    "        'crc32': f'0x{crc32:08x}',\n",
    "        'compressed_size': comp_size,\n",
    "        'uncompressed_size': uncomp_size,\n",
    "        'filename_length': name_len,\n",
    "        'extra_field_length': extra_len,\n",
    "        'filename': filename,\n",
    "        'data_start_offset': data_start,\n",
    "        'header_length': 30 + name_len + extra_len\n",
    "    }\n",
    "\n",
    "def get_compression_name(method):\n",
    "    \"\"\"获取压缩方法名称\"\"\"\n",
    "    methods = {\n",
    "        0: 'No Compression',\n",
    "        1: 'Shrunk',\n",
    "        2: 'Reduced 1',\n",
    "        3: 'Reduced 2', \n",
    "        4: 'Reduced 3',\n",
    "        5: 'Reduced 4',\n",
    "        6: 'Imploded',\n",
    "        8: 'Deflated',\n",
    "        9: 'Enhanced Deflated',\n",
    "        10: 'PKWare DCL',\n",
    "        12: 'BZIP2',\n",
    "        14: 'LZMA',\n",
    "        18: 'IBM TERSE',\n",
    "        19: 'IBM LZ77',\n",
    "        98: 'PPMd'\n",
    "    }\n",
    "    return methods.get(method, f'Unknown ({method})')\n",
    "\n",
    "def parse_dos_time(time, date):\n",
    "    \"\"\"解析DOS格式的日期时间\"\"\"\n",
    "    try:\n",
    "        second = (time & 0x1F) * 2\n",
    "        minute = (time >> 5) & 0x3F\n",
    "        hour = (time >> 11) & 0x1F\n",
    "        \n",
    "        day = date & 0x1F\n",
    "        month = (date >> 5) & 0x0F\n",
    "        year = ((date >> 9) & 0x7F) + 1980\n",
    "        \n",
    "        return f'{year:04d}-{month:02d}-{day:02d} {hour:02d}:{minute:02d}:{second:02d}'\n",
    "    except:\n",
    "        return 'Invalid date'\n",
    "\n",
    "def analyze_zip_headers(filedata, header1_offset, header2_offset):\n",
    "    \"\"\"分析ZIP文件的两个Local File Header\"\"\"\n",
    "    try:\n",
    "        data = filedata\n",
    "        print(f\"文件总大小: {len(data)} 字节\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # 解析第一个Header\n",
    "        print(f\"\\n第一个文件头 (偏移: 0x{header1_offset:04x}, {header1_offset} 字节):\")\n",
    "        print(\"-\" * 50)\n",
    "        header1 = parse_local_file_header(data, header1_offset)\n",
    "        print_header_info(header1)\n",
    "        \n",
    "        # 解析第二个Header  \n",
    "        print(f\"\\n第二个文件头 (偏移: 0x{header2_offset:04x}, {header2_offset} 字节):\")\n",
    "        print(\"-\" * 50)\n",
    "        header2 = parse_local_file_header(data, header2_offset)\n",
    "        print_header_info(header2)\n",
    "        \n",
    "        # 显示两个文件之间的关系\n",
    "        print(\"\\n文件关系分析:\")\n",
    "        print(\"-\" * 50)\n",
    "        analyze_relationship(header1, header2, data)\n",
    "        \n",
    "        return header1, header2\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误: 文件 {filename} 不存在\")\n",
    "    except Exception as e:\n",
    "        print(f\"解析错误: {e}\")\n",
    "\n",
    "def print_header_info(header):\n",
    "    \"\"\"打印Header信息\"\"\"\n",
    "    print(f\"  文件名: {header['filename']}\")\n",
    "    print(f\"  文件头长度: {header['header_length']} 字节\")\n",
    "    print(f\"  数据起始偏移: 0x{header['data_start_offset']:04x}\")\n",
    "    print(f\"  压缩方法: {header['compression_name']}\")\n",
    "    print(f\"  所需版本: {header['version_needed']}\")\n",
    "    print(f\"  标志: 0x{header['flags']:04x}\")\n",
    "    print(f\"  修改时间: {header['mod_time']}\")\n",
    "    print(f\"  CRC32: {header['crc32']}\")\n",
    "    print(f\"  压缩后大小: {header['compressed_size']} 字节\")\n",
    "    print(f\"  未压缩大小: {header['uncompressed_size']} 字节\")\n",
    "    print(f\"  文件名长度: {header['filename_length']} 字节\")\n",
    "    print(f\"  额外字段长度: {header['extra_field_length']} 字节\")\n",
    "\n",
    "def analyze_relationship(header1, header2, data):\n",
    "    \"\"\"分析两个文件之间的关系\"\"\"\n",
    "    # 计算第一个文件的数据结束位置\n",
    "    file1_data_end = header1['data_start_offset'] + header1['compressed_size']\n",
    "    \n",
    "    print(f\"第一个文件数据范围: 0x{header1['data_start_offset']:04x} - 0x{file1_data_end-1:04x}\")\n",
    "    print(f\"第二个文件头位置: 0x{header2['offset']:04x}\")\n",
    "    \n",
    "    gap = header2['offset'] - file1_data_end\n",
    "    if gap == 0:\n",
    "        print(\"文件排列: 紧密排列 (无间隙)\")\n",
    "    elif gap > 0:\n",
    "        print(f\"文件排列: 有 {gap} 字节间隙\")\n",
    "    else:\n",
    "        print(\"文件排列: 重叠 (可能数据大小不准确)\")\n",
    "    \n",
    "    # 检查第二个文件数据是否完整\n",
    "    file2_expected_end = header2['data_start_offset'] + header2['compressed_size']\n",
    "    actual_file_size = len(data)\n",
    "    \n",
    "    if file2_expected_end <= actual_file_size:\n",
    "        print(f\"第二个文件数据完整，结束于: 0x{file2_expected_end:04x}\")\n",
    "    else:\n",
    "        missing = file2_expected_end - actual_file_size\n",
    "        print(f\"第二个文件数据不完整，缺少 {missing} 字节\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4836bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件总大小: 1079 字节\n",
      "================================================================================\n",
      "\n",
      "第一个文件头 (偏移: 0x0000, 0 字节):\n",
      "--------------------------------------------------\n",
      "  文件名: no-flag-here\n",
      "  文件头长度: 42 字节\n",
      "  数据起始偏移: 0x002a\n",
      "  压缩方法: No Compression\n",
      "  所需版本: 2.0\n",
      "  标志: 0x0000\n",
      "  修改时间: 2025-10-17 11:45:14\n",
      "  CRC32: 0x4484e69e\n",
      "  压缩后大小: 960 字节\n",
      "  未压缩大小: 960 字节\n",
      "  文件名长度: 12 字节\n",
      "  额外字段长度: 0 字节\n",
      "\n",
      "第二个文件头 (偏移: 0x03ea, 1002 字节):\n",
      "--------------------------------------------------\n",
      "  文件名: also-not-here\n",
      "  文件头长度: 43 字节\n",
      "  数据起始偏移: 0x0415\n",
      "  压缩方法: Deflated\n",
      "  所需版本: 2.0\n",
      "  标志: 0x0000\n",
      "  修改时间: 2025-10-17 11:45:14\n",
      "  CRC32: 0x73290859\n",
      "  压缩后大小: 90 字节\n",
      "  未压缩大小: 30 字节\n",
      "  文件名长度: 13 字节\n",
      "  额外字段长度: 0 字节\n",
      "\n",
      "文件关系分析:\n",
      "--------------------------------------------------\n",
      "第一个文件数据范围: 0x002a - 0x03e9\n",
      "第二个文件头位置: 0x03ea\n",
      "文件排列: 紧密排列 (无间隙)\n",
      "第二个文件数据不完整，缺少 56 字节\n"
     ]
    }
   ],
   "source": [
    "C_zip = open(\"flag-is-not-stored-in-this-file.f58A66B51.zip\", 'rb').read()\n",
    "P_zip = bytes([a^b for a,b in zip(keystream, C_zip)])\n",
    "\n",
    "header1_offset = 0              # 第一个Local File Header的偏移量\n",
    "header2_offset = 1002           # 第二个Local File Header的偏移量\n",
    "\n",
    "# 分析Headers\n",
    "headers = analyze_zip_headers(P_zip, header1_offset, header2_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bc0bcf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "from datetime import datetime\n",
    "\n",
    "def datetime_to_dos_time(dt_str):\n",
    "    \"\"\"将日期时间字符串转换为DOS格式\"\"\"\n",
    "    try:\n",
    "        # 解析时间字符串 \"2025-10-17 11:45:14\"\n",
    "        dt = datetime.strptime(dt_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        # 转换为DOS格式\n",
    "        year = dt.year - 1980\n",
    "        month = dt.month\n",
    "        day = dt.day\n",
    "        hour = dt.hour\n",
    "        minute = dt.minute\n",
    "        second = dt.second // 2  # DOS时间以2秒为单位\n",
    "        \n",
    "        dos_date = (year << 9) | (month << 5) | day\n",
    "        dos_time = (hour << 11) | (minute << 5) | second\n",
    "        \n",
    "        return dos_time, dos_date\n",
    "    except:\n",
    "        # 如果解析失败，返回默认值\n",
    "        return 0x4a41, 0x54a5  # 2025-10-17 11:45:14 的DOS表示\n",
    "\n",
    "def reconstruct_zip_tail(header1, header2):\n",
    "    \"\"\"重建ZIP文件尾部\"\"\"\n",
    "    \n",
    "    # 计算Central Directory偏移 (第二个文件数据结束后)\n",
    "    cd_offset = header2['data_start_offset'] + header2['compressed_size']\n",
    "    \n",
    "    # 构建Central Directory\n",
    "    central_directory = b''\n",
    "    \n",
    "    # 文件1的CD记录 - 分步打包避免错误\n",
    "    time1, date1 = datetime_to_dos_time(header1['mod_time'])\n",
    "    \n",
    "    # 第一部分: 签名和版本信息 (8字节)\n",
    "    cd1_part1 = struct.pack('<LHH',\n",
    "        0x02014b50,           # signature\n",
    "        20, 20                # version made by, version needed\n",
    "    )\n",
    "    \n",
    "    # 第二部分: 标志和压缩方法 (4字节)\n",
    "    cd1_part2 = struct.pack('<HH',\n",
    "        0, 0                  # flags, compression method\n",
    "    )\n",
    "    \n",
    "    # 第三部分: 时间信息 (4字节)\n",
    "    cd1_part3 = struct.pack('<HH',\n",
    "        time1, date1          # mod time/date\n",
    "    )\n",
    "    \n",
    "    # 第四部分: CRC和大小信息 (12字节)\n",
    "    cd1_part4 = struct.pack('<LLL',\n",
    "        int(header1['crc32'], 16),  # crc32\n",
    "        header1['compressed_size'] & 0xFFFFFFFF,\n",
    "        header1['uncompressed_size'] & 0xFFFFFFFF\n",
    "    )\n",
    "    \n",
    "    # 第五部分: 长度信息 (10字节)\n",
    "    cd1_part5 = struct.pack('<HHHHH',\n",
    "        len(header1['filename']),  # file name length\n",
    "        0,                        # extra field length  \n",
    "        0,                        # file comment length\n",
    "        0,                        # disk number start\n",
    "        0                         # internal file attributes\n",
    "    )\n",
    "    \n",
    "    # 第六部分: 属性和偏移 (8字节)\n",
    "    cd1_part6 = struct.pack('<LL',\n",
    "        0,                       # external file attributes\n",
    "        header1['offset'] & 0xFFFFFFFF  # local header offset\n",
    "    )\n",
    "    \n",
    "    # 组合所有部分\n",
    "    cd1 = cd1_part1 + cd1_part2 + cd1_part3 + cd1_part4 + cd1_part5 + cd1_part6\n",
    "    cd1 += header1['filename'].encode('utf-8')\n",
    "    central_directory += cd1\n",
    "    \n",
    "    # 文件2的CD记录 - 同样的分步打包\n",
    "    time2, date2 = datetime_to_dos_time(header2['mod_time'])\n",
    "    \n",
    "    # 第一部分: 签名和版本信息\n",
    "    cd2_part1 = struct.pack('<LHH',\n",
    "        0x02014b50,\n",
    "        20, 20\n",
    "    )\n",
    "    \n",
    "    # 第二部分: 标志和压缩方法\n",
    "    cd2_part2 = struct.pack('<HH',\n",
    "        0, 8                    # compression method = deflated\n",
    "    )\n",
    "    \n",
    "    # 第三部分: 时间信息\n",
    "    cd2_part3 = struct.pack('<HH',\n",
    "        time2, date2\n",
    "    )\n",
    "    \n",
    "    # 第四部分: CRC和大小信息\n",
    "    cd2_part4 = struct.pack('<LLL',\n",
    "        int(header2['crc32'], 16),\n",
    "        header2['compressed_size'] & 0xFFFFFFFF,\n",
    "        header2['uncompressed_size'] & 0xFFFFFFFF\n",
    "    )\n",
    "    \n",
    "    # 第五部分: 长度信息\n",
    "    cd2_part5 = struct.pack('<HHHHH',\n",
    "        len(header2['filename']),\n",
    "        0, 0, 0, 0\n",
    "    )\n",
    "    \n",
    "    # 第六部分: 属性和偏移\n",
    "    cd2_part6 = struct.pack('<LL',\n",
    "        0,\n",
    "        header2['offset'] & 0xFFFFFFFF\n",
    "    )\n",
    "    \n",
    "    # 组合所有部分\n",
    "    cd2 = cd2_part1 + cd2_part2 + cd2_part3 + cd2_part4 + cd2_part5 + cd2_part6\n",
    "    cd2 += header2['filename'].encode('utf-8')\n",
    "    central_directory += cd2\n",
    "    \n",
    "    # 构建EOCD\n",
    "    cd_size = len(central_directory)\n",
    "    eocd = struct.pack('<LHHHHLLH',\n",
    "        0x06054b50,           # signature\n",
    "        0, 0,                 # disk numbers\n",
    "        2, 2,                 # entries in disk, total entries\n",
    "        cd_size,              # CD size\n",
    "        cd_offset,            # CD offset\n",
    "        0                     # comment length\n",
    "    )\n",
    "    \n",
    "    return central_directory, eocd, cd_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b45349c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'fvYY4wCFGSVIH4d05Xr2XZAcAjHo0vLqAjDWDNfl\\xe1f{cORruPTeD_zIp_cAn_be_reCOvErEd_BuT_ReDUNdaNcY_alSo_LeaD\\xd3^To_AmBiGuIty_OxShnyRcDUp1ogzv0aK2Q}LQyn'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd, eocd, offset = reconstruct_zip_tail(headers[0], headers[1])\n",
    "P_zip_tail = cd + eocd\n",
    "tail_key = [a^b for a, b in zip(P_zip_tail, C_zip[1135: 1274])]\n",
    "bytes([a^b for a,b in zip(tail_key, C_flag[1135: 1274])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-geek]",
   "language": "python",
   "name": "conda-env-.conda-geek-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
